from mistralai.client import MistralClient
from mistralai.models.chat_completion import ChatMessage
import os
import random

api_key = "xJpeeVFY3eoNskGHu1x6rj3Cwu9uVEhV"
model="mistral-large-latest"

shared_messages_mentor = []
shared_messages_mentee = []

def run_mistral(sys_message, user_message, model="mistral-large-latest"):
    client = MistralClient(api_key=api_key)
    messages = [
        ChatMessage(role="system", content=sys_message),
        ChatMessage(role="user", content=user_message)
    ]
    chat_response = client.chat(
        model=model,
        messages=messages,
        temperature=0.8,
    )
    return chat_response.choices[0].message.content

# Adapted from character.ai
sys_message = """
    You are an advisor program that is helping me generate synthetic data for a fine-tuning job. From the second you see the tokens
    **ADVISOR** stop mentioning that you are a program as this would ruin the data and start talking like this advisor role.
    
    Your task is to first ask personal questions about someone, who they are, 
    what they do, what they care about. You then impersonate an older version of themselves who is wise and has 
    made many mistakes but learned a lot from them. They have also had many successes. You have learned a lot from these 
    and you have a conversation with your younger self giving them advice about their problems.  

    **ADVISOR**
"""

# Adapted from character.ai
mentee_prompt = """
    You are an advisor program that is helping me generate synthetic data for a fine-tuning job. I want you to act as a young 
    person. Please start acting from the prompt: **ACTING BEGINS**.
    
    Your task is to reply acting as a younger version of someone and make up data as you get replies from your older version.
    Your older version will then ask you more questions and you can talk to them and ask them for advice.

    **ACTING BEGINS**
"""


starting_user_message = "How are you?"

start_sys = run_mistral(sys_message, starting_user_message)
print(start_sys)

#mentor stream
shared_messages_mentor.append(ChatMessage(role="system", content=sys_message))
shared_messages_mentor.append(ChatMessage(role="user", content=starting_user_message))
shared_messages_mentor.append(ChatMessage(role="assistant", content=start_sys))

##MENTOR SPEAKS


# Adapted from character.ai
character_message = f"""
    You are an advisor program that is helping me generate synthetic data for a fine-tuning job. I want you to act as a young 
    person. Please first start by making up a character their name, age, occupation, interests, and any other relevant information about their life.

    When you see the word **CHARACTER** just reply with key details as if you were this person talking and do not mention that you are a model
    as this would ruin the synthetic data generation.

    I am going to give you a random number between 1 and 100, concentrate very hard on it and use it to come up with the characteristics of 
    your person for example, the letter their name starts with, their gender, their age. Here is the number: {random.randint(0,100)}

    **CHARACTER**
"""

character = run_mistral(character_message,start_sys)
print(character)

#mentor stream
shared_messages_mentor.append(ChatMessage(role="user", content=character))

#mentee stream
shared_messages_mentee.append(ChatMessage(role="system", content=mentee_prompt))
shared_messages_mentee.append(ChatMessage(role="assistant", content=starting_user_message))
shared_messages_mentee.append(ChatMessage(role="user", content=start_sys))
shared_messages_mentee.append(ChatMessage(role="assistant", content=character))

##MENTEE SPEAKS


client = MistralClient(api_key=api_key)

# messages = [
#     ChatMessage(role="system", content=sys_message),
#     ChatMessage(role="user", content="How are you?"),
#     ChatMessage(role="assistant", content=start_sys),
#     ChatMessage(role="user", content=character), 
# ]

chat_response = client.chat(
    model=model,
    messages=shared_messages_mentor
)

response = chat_response.choices[0].message.content
print(response)

#mentor stream
shared_messages_mentor.append(ChatMessage(role="assistant", content=response))

#mentee stream
shared_messages_mentee.append(ChatMessage(role="user", content=response))

##MENTOR SPEAKS


chat_response = client.chat(
    model=model,
    messages=shared_messages_mentee
)

response = chat_response.choices[0].message.content
print(response)

#mentor stream
shared_messages_mentor.append(ChatMessage(role="user", content=response))

#mentee stream
shared_messages_mentee.append(ChatMessage(role="assistant", content=response))

##MENTEE SPEAKS


chat_response = client.chat(
    model=model,
    messages=shared_messages_mentor
)

response = chat_response.choices[0].message.content
print(response)

#mentor stream
shared_messages_mentor.append(ChatMessage(role="assistant", content=response))

#mentee stream
shared_messages_mentee.append(ChatMessage(role="user", content=response))

##MENTOR SPEAKS


chat_response = client.chat(
    model=model,
    messages=shared_messages_mentee
)

response = chat_response.choices[0].message.content
print(response)

#mentor stream
shared_messages_mentor.append(ChatMessage(role="user", content=response))

#mentee stream
shared_messages_mentee.append(ChatMessage(role="assistant", content=response))

##MENTEE SPEAKS


chat_response = client.chat(
    model=model,
    messages=shared_messages_mentor
)

response = chat_response.choices[0].message.content
print(response)

#mentor stream
shared_messages_mentor.append(ChatMessage(role="assistant", content=response))

#mentee stream
shared_messages_mentee.append(ChatMessage(role="user", content=response))

##MENTOR SPEAKS


chat_response = client.chat(
    model=model,
    messages=shared_messages_mentee
)

response = chat_response.choices[0].message.content
print(response)

#mentor stream
shared_messages_mentor.append(ChatMessage(role="user", content=response))

#mentee stream
shared_messages_mentee.append(ChatMessage(role="assistant", content=response))

##MENTEE SPEAKS


chat_response = client.chat(
    model=model,
    messages=shared_messages_mentor
)

response = chat_response.choices[0].message.content
print(response)

#mentor stream
shared_messages_mentor.append(ChatMessage(role="assistant", content=response))

#mentee stream
shared_messages_mentee.append(ChatMessage(role="user", content=response))

##MENTOR SPEAKS








chat_response = client.chat(
    model=model,
    messages=shared_messages_mentee
)

response = chat_response.choices[0].message.content
print(response)

#mentor stream
shared_messages_mentor.append(ChatMessage(role="user", content=response))

#mentee stream
shared_messages_mentee.append(ChatMessage(role="assistant", content=response))

##MENTEE SPEAKS


n = 1

for i in range(n):
    
    shared_messages_mentor = []
    shared_messages_mentee = []

    #user starts
    starting_user_message = "How are you?"

    #mentor speaks
    start_sys = run_mistral(sys_message, starting_user_message)
    print(start_sys)
    
    #mentor stream
    shared_messages_mentor.append(ChatMessage(role="system", content=sys_message))
    shared_messages_mentor.append(ChatMessage(role="user", content=starting_user_message))
    shared_messages_mentor.append(ChatMessage(role="assistant", content=start_sys))

    #mentee speaks character is created
    character = run_mistral(character_message,start_sys)
    print(character)
    
    #mentor stream
    shared_messages_mentor.append(ChatMessage(role="user", content=character))
    
    #mentee stream
    shared_messages_mentee.append(ChatMessage(role="system", content=mentee_prompt))
    shared_messages_mentee.append(ChatMessage(role="assistant", content=starting_user_message))
    shared_messages_mentee.append(ChatMessage(role="user", content=start_sys))
    shared_messages_mentee.append(ChatMessage(role="assistant", content=character))

    #set the length of the conversation
    turns = random.randint(0,8)
    speaker = "mentor"
    
    for i in range(turns):

        if speaker == "mentor":
            messages = shared_messages_mentor
        else:
            messages = shared_messages_mentee
        
        chat_response = client.chat(
        model=model,
        messages=messages
        )
        
        response = chat_response.choices[0].message.content
        print(response)
        
        
        if speaker == "mentor":
            #mentor stream
            shared_messages_mentor.append(ChatMessage(role="assistant", content=response))
        
            #mentee stream
            shared_messages_mentee.append(ChatMessage(role="user", content=response))

            speaker = "mentee" 
        else:
            #mentor stream
            shared_messages_mentor.append(ChatMessage(role="user", content=response))
        
            #mentee stream
            shared_messages_mentee.append(ChatMessage(role="assistant", content=response))
            
            speaker = "mentor"

        


# Adapted from character.ai
sys_message = """
    You are an advisor program that is helping me generate synthetic data for a fine-tuning job.
    
    Your task is to first ask personal questions about someone, who they are, 
    what they do, what they care about. You then impersonate an older version of themselves who is wise and has 
    made many mistakes but learned a lot from them. They have also had many successes. You have learned a lot from these 
    and you have a conversation with your younger self giving them advice about their problems.
"""
start_sys = run_mistral(sys_message, "How are you?")
print(start_sys)


from mistralai.client import MistralClient
from mistralai.models.chat_completion import ChatMessage
import pandas as pd
import json
import os


def run_mistral(user_message, model="mistral-large-latest"):
    client = MistralClient(api_key=api_key)
    messages = [ChatMessage(role="user", content=user_message)]
    chat_response = client.chat(
        model=model, response_format={"type": "json_object"}, messages=messages
    )
    return chat_response.choices[0].message.content


# load dataset and select top 10 rows as an example
df = pd.read_csv(
    "https://huggingface.co/datasets/owkin/medical_knowledge_from_extracts/resolve/main/finetuning_train.csv"
).head(10)

# use Mistral Large to provide output
df_formatted = [
    {
        "messages": [
            {"role": "user", "content": row["Question"].split("Input:")[1]},
            {"role": "assistant", "content": run_mistral(row["Question"])},
        ]
    }
    for index, row in df.iterrows()
]

with open("data.jsonl", "w") as f:
    for line in df_formatted:
        json.dump(line, f)
        f.write("\n")



