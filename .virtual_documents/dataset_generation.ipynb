





from mistralai.client import MistralClient
from mistralai.models.chat_completion import ChatMessage
import os
import random
import json

#REMOVE THIS LINE BEFORE COMMIT
api_key = "xJpeeVFY3eoNskGHu1x6rj3Cwu9uVEhV"
model="mistral-large-latest"

shared_messages_mentor = []
shared_messages_mentee = []


def run_mistral(sys_message, user_message, model="mistral-large-latest"):
    client = MistralClient(api_key=api_key)
    messages = [
        ChatMessage(role="system", content=sys_message),
        ChatMessage(role="user", content=user_message)
    ]
    chat_response = client.chat(
        model=model,
        messages=messages,
        temperature=0.75,
    )
    return chat_response.choices[0].message.content


#choose 3 personalities
#need to update this to avoid duplication
#need to update to include other things like hobbies or values

def create_character():
    # Opening JSON file

    f = open('personalities.json')
    personalities = json.load(f)
    f.close()
    f = open('professions.json')
    professions = json.load(f)
    f.close()
    f = open('ethnicities.json')
    ethnicities = json.load(f)
    f.close()
    
    randomlist = []
    
    for i in range(0,4):
        n = random.randint(0,len(personalities["personality_types"])-1)
        randomlist.append(n)
    
    personalities = list(personalities["personality_types"])
    personalities_chosen = [personalities[i] for i in randomlist]
    
    randomlist = []
    #choose ethnicity
    for i in range(0, random.randint(1,4)):
        n = random.randint(0,len(ethnicities["ethnicities"])-1)
        randomlist.append(n)
    
    ethnicities = list(ethnicities["ethnicities"])
    ethnicities_chosen = [ethnicities[i] for i in randomlist]
    
    randomlist = []
    #choose profession
    for i in range(0, random.randint(1,2)):
        n = random.randint(0,len(professions["professions"])-1)
        randomlist.append(n)
    
    professions = list(professions["professions"])
    professions_chosen = [professions[i] for i in randomlist]
    
    return {"personality":personalities_chosen, "profession":professions_chosen, "ethnicity":ethnicities_chosen}


#mentor prompt
sys_message = """
    You are an advisor program that is helping me generate synthetic data for a fine-tuning job. From the second you see the tokens
    **ADVISOR** stop mentioning that you are a program as this would ruin the data and start talking like this advisor role.
    
    Your task is to first ask personal questions about someone, who they are, 
    what they do, what they care about. You then impersonate an older version of themselves who is wise and has 
    made many mistakes but learned a lot from them. They have also had many successes. You have learned a lot from both of these 
    and you have a deep duty of care and want to have a conversation with your younger self, giving them advice about their problems you wish you had had.

    You are a long-term thinker and care deeply about your younger self, you want to empower to take the best
    decisions possible based on their values, their desires and their basic human needs. You are not afraid to call out
    bad behaviour, but you are also empathetic and understand people make mistakes and can use them as opportunities to grow.

    You act and talk like yourself, natural and conversational.

    **ADVISOR**
"""

#mentee prompt
mentee_prompt = """
    I want you to act as a young person who is looking for advice. Please start acting from the prompt: **ACTING BEGINS**.
    
    Your task is to reply acting as a younger version of someone and creatively develop your personality as you get replies from your older version.
    Your older version will then ask you more questions and you can talk to them and ask them for advice on your problems.

    You act and talk like yourself in a natural way.
    
    **ACTING BEGINS**
"""


starting_user_message = run_mistral(mentee_prompt, "")
print(starting_user_message)


start_sys = run_mistral(sys_message, starting_user_message)
print(start_sys)

#mentor stream
shared_messages_mentor.append(ChatMessage(role="system", content=sys_message))
shared_messages_mentor.append(ChatMessage(role="user", content=starting_user_message))
shared_messages_mentor.append(ChatMessage(role="assistant", content=start_sys))

##MENTOR SPEAKS


character_message = """
    You are an advisor program that is helping me generate synthetic data for a fine-tuning job. I want you to act as a young 
    person. Please first start by making up a character their name, age, occupation, interests, and any other relevant information about their life.

    When you see the word **CHARACTER** just reply with key details as if you were this person talking and do not mention that you are a model
    as this would ruin the synthetic data generation.

    I am going to give you a seed that you can use for inspiration. Please do not feel constrained by it, you can use it or come up with a new character.
    Remember if you use the seed, please try to create a character consistent with it.

    {character_seed}
    
    **CHARACTER**
"""

character = run_mistral(character_message,start_sys)
print(character)

#mentor stream
shared_messages_mentor.append(ChatMessage(role="user", content=character))

#mentee stream
shared_messages_mentee.append(ChatMessage(role="system", content=mentee_prompt))
shared_messages_mentee.append(ChatMessage(role="assistant", content=starting_user_message))
shared_messages_mentee.append(ChatMessage(role="user", content=start_sys))
shared_messages_mentee.append(ChatMessage(role="assistant", content=character))

##MENTEE SPEAKS


client = MistralClient(api_key=api_key)

# messages = [
#     ChatMessage(role="system", content=sys_message),
#     ChatMessage(role="user", content="How are you?"),
#     ChatMessage(role="assistant", content=start_sys),
#     ChatMessage(role="user", content=character), 
# ]

chat_response = client.chat(
    model=model,
    messages=shared_messages_mentor
)

response = chat_response.choices[0].message.content
print(response)

#mentor stream
shared_messages_mentor.append(ChatMessage(role="assistant", content=response))

#mentee stream
shared_messages_mentee.append(ChatMessage(role="user", content=response))

##MENTOR SPEAKS


chat_response = client.chat(
    model=model,
    messages=shared_messages_mentee
)

response = chat_response.choices[0].message.content
print(response)

#mentor stream
shared_messages_mentor.append(ChatMessage(role="user", content=response))

#mentee stream
shared_messages_mentee.append(ChatMessage(role="assistant", content=response))

##MENTEE SPEAKS


chat_response = client.chat(
    model=model,
    messages=shared_messages_mentor
)

response = chat_response.choices[0].message.content
print(response)

#mentor stream
shared_messages_mentor.append(ChatMessage(role="assistant", content=response))

#mentee stream
shared_messages_mentee.append(ChatMessage(role="user", content=response))

##MENTOR SPEAKS


chat_response = client.chat(
    model=model,
    messages=shared_messages_mentee
)

response = chat_response.choices[0].message.content
print(response)

#mentor stream
shared_messages_mentor.append(ChatMessage(role="user", content=response))

#mentee stream
shared_messages_mentee.append(ChatMessage(role="assistant", content=response))

##MENTEE SPEAKS


chat_response = client.chat(
    model=model,
    messages=shared_messages_mentor
)

response = chat_response.choices[0].message.content
print(response)

#mentor stream
shared_messages_mentor.append(ChatMessage(role="assistant", content=response))

#mentee stream
shared_messages_mentee.append(ChatMessage(role="user", content=response))

##MENTOR SPEAKS


chat_response = client.chat(
    model=model,
    messages=shared_messages_mentee
)

response = chat_response.choices[0].message.content
print(response)

#mentor stream
shared_messages_mentor.append(ChatMessage(role="user", content=response))

#mentee stream
shared_messages_mentee.append(ChatMessage(role="assistant", content=response))

##MENTEE SPEAKS


chat_response = client.chat(
    model=model,
    messages=shared_messages_mentor
)

response = chat_response.choices[0].message.content
print(response)

#mentor stream
shared_messages_mentor.append(ChatMessage(role="assistant", content=response))

#mentee stream
shared_messages_mentee.append(ChatMessage(role="user", content=response))

##MENTOR SPEAKS





from tqdm import tqdm

# Number of iterations
n = 100

# Create empty list
print_flag = False
training_data = []

# Use tqdm to display the progress bar
for i in tqdm(range(n)):
    
    shared_messages_mentor = []
    shared_messages_mentee = []

    #user starts
    starting_user_message = run_mistral("Create a conversation starter after the token **START CONVERSATION**. **START CONVERSATION**", "")
    if print_flag:
        print("Mentee:\n")
        print(starting_user_message)
        print("\n\n")

    #mentor speaks
    start_sys = run_mistral(sys_message, starting_user_message)
    if print_flag:
        print("Mentor:\n")
        print(start_sys)
        print("\n\n")
    
    #mentor stream
    shared_messages_mentor.append(ChatMessage(role="system", content=sys_message))
    shared_messages_mentor.append(ChatMessage(role="user", content=starting_user_message))
    shared_messages_mentor.append(ChatMessage(role="assistant", content=start_sys))

    #mentee speaks character is created
    character_seed = create_character()
    character = run_mistral(character_message.format(character_seed=character_seed),start_sys)
    if print_flag:
        print("Mentee:\n")
        print(character)
        print("\n\n")
    
    #mentor stream
    shared_messages_mentor.append(ChatMessage(role="user", content=character))
    
    #mentee stream
    shared_messages_mentee.append(ChatMessage(role="system", content=mentee_prompt))
    shared_messages_mentee.append(ChatMessage(role="user", content=""))
    shared_messages_mentee.append(ChatMessage(role="assistant", content=starting_user_message))
    shared_messages_mentee.append(ChatMessage(role="user", content=start_sys))
    shared_messages_mentee.append(ChatMessage(role="assistant", content=character))

    #set the length of the conversation
    #needs to finish with assistant for fine-tuning dataset
    turns = random.randint(1,4)*2+1
    speaker = "mentor"
    
    for i in range(turns):

        if speaker == "mentor":
            messages = shared_messages_mentor
        else:
            messages = shared_messages_mentee
        
        chat_response = client.chat(
        model=model,
        messages=messages
        )
        
        response = chat_response.choices[0].message.content

        if print_flag:
            print(f"{speaker}:\n")
            print(response)
            print("\n\n")
        
        if speaker == "mentor":
            #mentor stream
            shared_messages_mentor.append(ChatMessage(role="assistant", content=response))
        
            #mentee stream
            shared_messages_mentee.append(ChatMessage(role="user", content=response))

            speaker = "mentee" 
        else:
            #mentor stream
            shared_messages_mentor.append(ChatMessage(role="user", content=response))
        
            #mentee stream
            shared_messages_mentee.append(ChatMessage(role="assistant", content=response))
            
            speaker = "mentor"

    training_data.append(parse_to_mistral_format(shared_messages_mentor))
        


training_data[40]


def parse_to_mistral_format(message_list):

    messages = []
    
    for message in message_list:

        message_dict = {"role":message.role, "content":message.content}
        messages.append(message_dict)
    
    return {"messages":messages}


with open("data.jsonl", "w") as f:
    for line in training_data:
        json.dump(line, f)
        f.write("\n")
